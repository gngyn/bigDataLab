{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "\n",
    "#Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "#spacy and nltk\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#visuals\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#pandas for reading excel file\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREPARING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"allData.csv\")\n",
    "data = df[\"JOB DESCRIPTION\"]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords.words(\"english\")\n",
    "stopwords.extend(['actual', 'additional', 'advancement_opportunitie', 'airline', 'also', 'always', 'andor', 'anywhere',\n",
    "                  'applicable', 'applicant', 'application', 'apply', 'approximately', 'area', 'available', 'aviation', 'away',\n",
    "                  'benefit', 'bonus', 'candidate', 'club', 'color', 'company', 'companypaid',\n",
    "                  'compensation', 'complete', 'condition', 'consideration', 'covid', 'crew', 'current',\n",
    "                  'date', 'degree', 'demonstrate', 'disability', 'do',  'duty',\n",
    "                  'eg', 'employee', 'employer', 'employment', 'equity', 'especially', 'ethic', 'even', 'ever', \n",
    "                  'fixedwe', 'flight', 'fly', 'fom', 'gather', 'gender', 'get', 'gs', 'healthcare', 'hire', 'hiring', 'however', 'incentive',\n",
    "                  'include', 'income', 'insurance', 'job', 'least', 'letter', 'little', 'look', 'make', 'manner', 'many', 'marital',\n",
    "                  'match', 'medical', 'memeber', 'military', 'much', 'nd', 'offer', 'nearly', 'often', 'oh', 'on', 'opportunity',\n",
    "                  'other', 'otherwise', 'package', 'parental', 'part', 'passport', 'pay', 'payment', 'perform', 'person', 'pilot', 'policy',\n",
    "                  'position', 'primary', 'pregnancy', 'race', 'rd', 're', 'regard', 'relate', 'religion', 'resume', 'retire', 'retirement',\n",
    "                  'salary', 'self', 'set', 'sex', 'skill', 'sometimes', 'special', 'state', 'st', 'still', 'stipend', 'submit', 'total', 'truly', 'type',\n",
    "                  'unusual', 'use', 'veteran', 'well', 'whole', 'will', 'work'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REMOVE PUNCTUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "\n",
    "for text in data:\n",
    "    if isinstance(text, str):\n",
    "        temp.append(text.replace('\\n', ' '))\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "\n",
    "data = temp\n",
    "\n",
    "data = [re.sub(r'[^\\w\\s]','', text) for text in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeStopwords(texts):\n",
    "    returnList = []\n",
    "    for text in texts:\n",
    "        textArr = text.split(' ')\n",
    "        string = \" \".join([i for i in textArr if i.lower() not in stopwords])\n",
    "        returnList.append(string)\n",
    "        \n",
    "    return returnList\n",
    "\n",
    "stopwordsData = removeStopwords(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "noURLData = [re.sub('http://\\S+|https://\\S+', '', text) for text in stopwordsData]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEMMATIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mission provide airborne platform support specific research development program provide method validation field collect datum aircraft fly maintain manage professional staff test pilot certify maintenance technician administrative personnel first priority safety operation conduct use procedure equipment meet exceed requirement result various past airborne testing program missionspecific procedure develop procedure provide safe effective successful operation create support early airtoair collision avoidance research program sponsor need extensive airborne testing increase expand support variety program currently operate experimentally certificate commercially derivative airborne test bed range size small single engine large turboprop corporate jet essential member team responsible conducting mission safety test planning operate highly modify man unmanned aircraft purpose call evaluate handling quality performance modify test bed aircraft operate aircraft sensor datum collection flight test duty directly responsible safe efficient conduct flight assign effectively small team engage engineering customer ensure smooth aircraft integration process engineering customer understand project scope build schedule translate engineering requirement test plan include profile test card analyze test manage logistic coordinate airspace actively contribute technical information test planning meeting preflight briefing debriefing engineering project personnel result test flight ground include recommendation lesson learn sop rule regulation proper safety risk mitigation method ensure compliance federal local foreign regulation policy procedure specify flight operation manual review comply range operating procedure day day administrative responsibility require operation department safety training record keep navigation toolsdatabase maintenance process development visible representative act tact decorum ensure efficient safe operation practical knowledge test procedure year test experience highly prefer certificate privilege commercial privilege highly desire consider minimum certificate previously rate extensive experience experience desire jet aircraft experience rating desire single engine desirable hour include hour turbine hour time equivalent highly prefer SETP recognize skill necessary effectively variety individual department organization willingness irregular hour day ability travel short notice airworthiness process procedure system desire click httphrwebmitedubenefit select subject preemployment background investigation able obtain maintain secret level dod security clearance qualified applicant receive discriminate basis sexual orientation identity national origin age status status genetic information citizenship require\n"
     ]
    }
   ],
   "source": [
    "def lemmatization(texts, allowed_postags=[\"NOUN\", \"ADJ\", \"VERB\", \"ADV\"]):\n",
    "    nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "    texts_out = []\n",
    "    for text in texts:\n",
    "        doc = nlp(text)\n",
    "        new_text = []\n",
    "        for token in doc:\n",
    "            if token.pos_ in allowed_postags:\n",
    "                new_text.append(token.lemma_)\n",
    "        final = \" \".join(new_text)\n",
    "        texts_out.append(final)\n",
    "    return (texts_out)\n",
    "\n",
    "lemmatizedTexts = lemmatization(noURLData)\n",
    "\n",
    "print(lemmatizedTexts[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOWERCASE WORDS, REMOVE SHORT AND LONG WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mission', 'provide', 'airborne', 'platform', 'support', 'specific', 'research', 'development', 'program', 'provide', 'method', 'validation', 'field', 'collect', 'datum', 'aircraft', 'fly', 'maintain', 'manage', 'professional', 'staff', 'test', 'pilot', 'certify', 'maintenance', 'technician', 'administrative', 'personnel', 'first', 'priority', 'safety', 'operation', 'conduct', 'use', 'procedure', 'equipment', 'meet', 'exceed', 'requirement', 'result', 'various', 'past', 'airborne', 'testing', 'program', 'missionspecific', 'procedure', 'develop', 'procedure', 'provide', 'safe', 'effective', 'successful', 'operation', 'create', 'support', 'early', 'airtoair', 'collision', 'avoidance', 'research', 'program', 'sponsor', 'need', 'extensive', 'airborne', 'testing', 'increase', 'expand', 'support', 'variety', 'program', 'currently', 'operate', 'experimentally', 'certificate', 'commercially', 'derivative', 'airborne', 'test', 'bed', 'range', 'size', 'small', 'single', 'engine', 'large', 'turboprop', 'corporate', 'jet', 'essential', 'member', 'team', 'responsible', 'conducting', 'mission', 'safety', 'test', 'planning', 'operate', 'highly', 'modify', 'man', 'unmanned', 'aircraft', 'purpose', 'call', 'evaluate', 'handling', 'quality', 'performance', 'modify', 'test', 'bed', 'aircraft', 'operate', 'aircraft', 'sensor', 'datum', 'collection', 'flight', 'test', 'duty', 'directly', 'responsible', 'safe', 'efficient', 'conduct', 'flight', 'assign', 'effectively', 'small', 'team', 'engage', 'engineering', 'customer', 'ensure', 'smooth', 'aircraft', 'integration', 'process', 'engineering', 'customer', 'understand', 'project', 'scope', 'build', 'schedule', 'translate', 'engineering', 'requirement', 'test', 'plan', 'include', 'profile', 'test', 'card', 'analyze', 'test', 'manage', 'logistic', 'coordinate', 'airspace', 'actively', 'contribute', 'technical', 'information', 'test', 'planning', 'meeting', 'preflight', 'briefing', 'debriefing', 'engineering', 'project', 'personnel', 'result', 'test', 'flight', 'ground', 'include', 'recommendation', 'lesson', 'learn', 'sop', 'rule', 'regulation', 'proper', 'safety', 'risk', 'mitigation', 'method', 'ensure', 'compliance', 'federal', 'local', 'foreign', 'regulation', 'policy', 'procedure', 'specify', 'flight', 'operation', 'manual', 'review', 'comply', 'range', 'operating', 'procedure', 'day', 'day', 'administrative', 'responsibility', 'require', 'operation', 'department', 'safety', 'training', 'record', 'keep', 'navigation', 'toolsdatabase', 'maintenance', 'process', 'development', 'visible', 'representative', 'act', 'tact', 'decorum', 'ensure', 'efficient', 'safe', 'operation', 'practical', 'knowledge', 'test', 'procedure', 'year', 'test', 'experience', 'highly', 'prefer', 'certificate', 'privilege', 'commercial', 'privilege', 'highly', 'desire', 'consider', 'minimum', 'certificate', 'previously', 'rate', 'extensive', 'experience', 'experience', 'desire', 'jet', 'aircraft', 'experience', 'rating', 'desire', 'single', 'engine', 'desirable', 'hour', 'include', 'hour', 'turbine', 'hour', 'time', 'equivalent', 'highly', 'prefer', 'setp', 'recognize', 'skill', 'necessary', 'effectively', 'variety', 'individual', 'department', 'organization', 'willingness', 'irregular', 'hour', 'day', 'ability', 'travel', 'short', 'notice', 'airworthiness', 'process', 'procedure', 'system', 'desire', 'click', 'select', 'subject', 'preemployment', 'background', 'investigation', 'able', 'obtain', 'maintain', 'secret', 'level', 'dod', 'security', 'clearance', 'qualified', 'applicant', 'receive', 'discriminate', 'basis', 'sexual', 'orientation', 'identity', 'national', 'origin', 'age', 'status', 'status', 'genetic', 'information', 'citizenship', 'require']\n"
     ]
    }
   ],
   "source": [
    "def gen_words(texts):\n",
    "    final = []\n",
    "    for text in texts:\n",
    "        new = gensim.utils.simple_preprocess(text, deacc=True)\n",
    "        final.append(new)\n",
    "    return (final)\n",
    "\n",
    "dataWords = gen_words(lemmatizedTexts)\n",
    "\n",
    "print (dataWords[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATE BIGRAMS AND TRIGRAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mission', 'provide', 'airborne', 'platform', 'support', 'specific', 'research', 'development', 'program', 'provide', 'method', 'validation', 'field', 'collect', 'datum', 'aircraft', 'fly', 'maintain', 'manage', 'professional', 'staff', 'test', 'pilot', 'certify', 'maintenance', 'technician', 'administrative', 'personnel', 'first', 'priority', 'safety', 'operation', 'conduct', 'use', 'procedure', 'equipment', 'meet', 'exceed', 'requirement', 'result', 'various', 'past', 'airborne', 'testing', 'program', 'missionspecific', 'procedure', 'develop', 'procedure', 'provide', 'safe', 'effective', 'successful', 'operation', 'create', 'support', 'early', 'airtoair', 'collision', 'avoidance', 'research', 'program', 'sponsor', 'need', 'extensive', 'airborne', 'testing', 'increase', 'expand', 'support', 'variety', 'program', 'currently', 'operate', 'experimentally', 'certificate', 'commercially', 'derivative', 'airborne', 'test', 'bed', 'range', 'size', 'small', 'single_engine', 'large', 'turboprop', 'corporate', 'jet', 'essential', 'member', 'team', 'responsible', 'conducting', 'mission', 'safety', 'test', 'planning', 'operate', 'highly', 'modify', 'man_unmanned', 'aircraft', 'purpose', 'call', 'evaluate', 'handling', 'quality', 'performance', 'modify', 'test', 'bed', 'aircraft', 'operate', 'aircraft', 'sensor', 'datum_collection', 'flight', 'test', 'duty', 'directly', 'responsible', 'safe', 'efficient', 'conduct', 'flight', 'assign', 'effectively', 'small', 'team', 'engage', 'engineering', 'customer', 'ensure', 'smooth', 'aircraft', 'integration', 'process', 'engineering', 'customer', 'understand', 'project', 'scope', 'build', 'schedule', 'translate', 'engineering', 'requirement', 'test', 'plan', 'include', 'profile', 'test', 'card', 'analyze', 'test', 'manage', 'logistic', 'coordinate', 'airspace', 'actively', 'contribute', 'technical', 'information', 'test', 'planning', 'meeting', 'preflight', 'briefing_debriefing', 'engineering', 'project', 'personnel', 'result', 'test', 'flight', 'ground', 'include', 'recommendation', 'lesson', 'learn', 'sop', 'rule', 'regulation', 'proper', 'safety', 'risk_mitigation', 'method', 'ensure', 'compliance', 'federal', 'local', 'foreign', 'regulation', 'policy', 'procedure', 'specify', 'flight', 'operation', 'manual', 'review', 'comply', 'range', 'operating', 'procedure', 'day', 'day', 'administrative', 'responsibility', 'require', 'operation', 'department', 'safety', 'training', 'record', 'keep', 'navigation', 'toolsdatabase', 'maintenance', 'process', 'development', 'visible_representative', 'act_tact_decorum', 'ensure', 'efficient', 'safe', 'operation', 'practical', 'knowledge', 'test', 'procedure', 'year', 'test', 'experience', 'highly', 'prefer', 'certificate', 'privilege', 'commercial', 'privilege', 'highly', 'desire', 'consider', 'minimum', 'certificate', 'previously', 'rate', 'extensive', 'experience', 'experience', 'desire', 'jet', 'aircraft', 'experience', 'rating', 'desire', 'single_engine', 'desirable', 'hour', 'include', 'hour', 'turbine', 'hour', 'time', 'equivalent', 'highly', 'prefer', 'setp', 'recognize', 'skill', 'necessary', 'effectively', 'variety', 'individual', 'department', 'organization', 'willingness_irregular', 'hour', 'day', 'ability', 'travel', 'short_notice', 'airworthiness', 'process', 'procedure', 'system', 'desire', 'click', 'select', 'subject', 'preemployment', 'background', 'investigation', 'able', 'obtain', 'maintain', 'secret', 'level', 'dod', 'security', 'clearance', 'qualified', 'applicant', 'receive', 'discriminate', 'basis', 'sexual_orientation_identity', 'national_origin_age', 'status', 'status', 'genetic', 'information', 'citizenship', 'require']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bigram_phrases = gensim.models.Phrases(dataWords, min_count=2, threshold=100)\n",
    "trigram_phrases = gensim.models.Phrases(bigram_phrases[dataWords], threshold=100, min_count=2)\n",
    "\n",
    "bigram = gensim.models.phrases.Phraser(bigram_phrases)\n",
    "trigram = gensim.models.phrases.Phraser(trigram_phrases)\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return([bigram[doc] for doc in texts])\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return ([trigram[bigram[doc]] for doc in texts])\n",
    "\n",
    "dataBigrams = make_bigrams(dataWords)\n",
    "dataFinal = make_trigrams(dataBigrams)\n",
    "\n",
    "\n",
    "#remove bigrams\n",
    "\n",
    "print(dataFinal[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nlength = (len(corpus))\\nprint(len(id2word))\\ntotalCount = defaultdict(int)\\n\\nfor wordID, wordCount in itertools.chain.from_iterable(corpus):\\n    totalCount[wordID] += wordCount\\n\\nsortedList = sorted(totalCount.items(), key=lambda x: x[1], reverse=True)\\n\\nnum = len(sortedList) * 3 // 20\\n\\ntopWords = []\\n\\nfor i in range(num):\\n    index = sortedList[i][0]\\n    topWords.append(id2word[index])\\nprint(len(topWords))\\nprint(topWords)\\n\\n\\n\\nwith open('topWords.csv', 'w', newline = '') as file:\\n    writer = csv.writer(file)\\n    \\n    for word in topWords:\\n        writer.writerow([word])\\n#within each doc, different num of words and freqs\\n# go through each doc, and\\n\\n#every word per document is sorted by ascending order\\n\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word = corpora.Dictionary(dataFinal)\n",
    "\n",
    "texts = dataFinal\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "'''\n",
    "length = (len(corpus))\n",
    "print(len(id2word))\n",
    "totalCount = defaultdict(int)\n",
    "\n",
    "for wordID, wordCount in itertools.chain.from_iterable(corpus):\n",
    "    totalCount[wordID] += wordCount\n",
    "\n",
    "sortedList = sorted(totalCount.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "num = len(sortedList) * 3 // 20\n",
    "\n",
    "topWords = []\n",
    "\n",
    "for i in range(num):\n",
    "    index = sortedList[i][0]\n",
    "    topWords.append(id2word[index])\n",
    "print(len(topWords))\n",
    "print(topWords)\n",
    "\n",
    "\n",
    "\n",
    "with open('topWords.csv', 'w', newline = '') as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    for word in topWords:\n",
    "        writer.writerow([word])\n",
    "#within each doc, different num of words and freqs\n",
    "# go through each doc, and\n",
    "\n",
    "#every word per document is sorted by ascending order\n",
    "'''\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NUMBER OF TOPICS TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCoherenceValues(corpus, id2word, k):\n",
    "    ldaTest = gensim.models.ldamodel.LdaModel(corpus=corpus, num_topics=k, id2word=id2word, chunksize=100, passes= 20, alpha = 'auto', random_state= 100, update_every=1)\n",
    " \n",
    "    \n",
    "    # * different measures\n",
    "    # * c_v, umass, c_uci\n",
    "    \n",
    "    coherenceTest = CoherenceModel(model=ldaTest, corpus=corpus, texts=texts, dictionary= id2word, coherence='c_uci')\n",
    "    coherenceScore = coherenceTest.get_coherence()\n",
    "    print('Completed ' + str(k) + ' topics')\n",
    "    print('Coherence Score: ', round(coherenceScore, 5))\n",
    "    print('\\n')\n",
    "    return coherenceScore\n",
    "\n",
    "def computePerplexityValues(corpus, id2word, k):\n",
    "    ldaTest = gensim.models.ldamodel.LdaModel(corpus=corpus, num_topics=k, id2word=id2word, chunksize=100, passes= 20, alpha = 'auto', random_state= 100, update_every=1)\n",
    "    perplexScore = ldaTest.log_perplexity(corpus)\n",
    "    print('Completed ' + str(k) + ' topics')\n",
    "    print('Perplexity Value: ', perplexScore)\n",
    "    print('\\n')\n",
    "    return perplexScore\n",
    "\n",
    "#coherence testing\n",
    "if not True:\n",
    "    topicNum = []\n",
    "    coherenceScore = []\n",
    "    for k in range(1, 26):\n",
    "        # get the coherence score for the given parameters\n",
    "        cv = computeCoherenceValues(corpus=corpus, id2word=id2word, k=k)\n",
    "        topicNum.append(k)   \n",
    "        coherenceScore.append(cv)\n",
    "        \n",
    "    plt.plot(topicNum, coherenceScore, marker = 'o')\n",
    "    plt.xlabel('Number of Topics')\n",
    "    plt.ylabel('Values')\n",
    "    plt.title('C_UCI Coherence Values of Different Number of Topics')\n",
    "    plt.savefig('test.png', bbox_inches = 'tight')\n",
    "        \n",
    "#perplexity testing\n",
    "if not True:\n",
    "    topicNum = []\n",
    "    perplexityScore = []\n",
    "    for k in range(1, 20):\n",
    "        # get the coherence score for the given parameters\n",
    "        pv = computePerplexityValues(corpus=corpus, id2word=id2word, k=k)\n",
    "        topicNum.append(k)   \n",
    "        perplexityScore.append(pv)\n",
    "        \n",
    "    plt.plot(topicNum, perplexityScore, marker = 'o')\n",
    "    plt.xlabel('Number of Topics')\n",
    "    plt.ylabel('Values')\n",
    "    plt.title('Perplexity Values of Different Number of Topics')\n",
    "    plt.savefig('PerplexityChart3.png', bbox_inches = 'tight')\n",
    "        \n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldaModel = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=id2word, num_topics=9, random_state=100, \n",
    "                                           update_every=1, chunksize= 100, passes=20, alpha=\"auto\")\n",
    "\n",
    "# coherenceModel = CoherenceModel(model=ldaModel, texts=texts, dictionary=id2word, coherence='c_v')\n",
    "# print('Coherence value of LDA model: ', round(coherenceModel.get_coherence(), 5))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(ldaModel, corpus, id2word, mds=\"mmds\", R=20)\n",
    "vis\n",
    "\n",
    "pyLDAvis.save_html(vis, 'LDAdemo.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5cfb3197d363e0993c68f56884398545d23c75318c4aeb3137c59dbd664f5459"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
